# -*- coding: utf-8 -*-
"""BIOA_vs_Other_Algorithms_Comparison.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1your_drive_link_here
"""

# Install required packages
!pip install tsplib95 matplotlib numpy scipy

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import time
import tsplib95
from typing import List, Tuple, Dict, Callable
import requests
from scipy.spatial import distance_matrix
from matplotlib import rcParams

# Set high-resolution parameters
rcParams['figure.dpi'] = 1200
rcParams['savefig.dpi'] = 1200
rcParams['savefig.bbox'] = 'tight'
rcParams['font.size'] = 12

class BaseTSPOptimizer:
    """Base class for all TSP optimizers"""

    def __init__(self, population_size: int = 50, max_iterations: int = 1000):
        self.population_size = population_size
        self.max_iterations = max_iterations
        self.best_solution = None
        self.best_distance = float('inf')
        self.convergence_history = []

    def calculate_distance(self, route: List[int], distance_matrix: np.ndarray) -> float:
        """Calculate total distance of a route"""
        total_distance = 0
        for i in range(len(route)):
            total_distance += distance_matrix[route[i-1]][route[i]]
        return total_distance

    def initialize_population(self, num_cities: int) -> List[List[int]]:
        """Initialize population with random routes"""
        population = []
        for _ in range(self.population_size):
            route = list(range(num_cities))
            random.shuffle(route)
            population.append(route)
        return population

class BIOA_TSP_Solver(BaseTSPOptimizer):
    """Beagle Inspired Optimization Algorithm for TSP"""

    def __init__(self, population_size: int = 50, max_iterations: int = 1000):
        super().__init__(population_size, max_iterations)

    def sniff_mutate(self, route: List[int]) -> List[int]:
        """Beagle-inspired mutation operator"""
        child = route.copy()

        # Multiple mutation strategies
        mutation_type = random.choice([1, 2, 3])

        if mutation_type == 1:  # Swap mutation
            i, j = random.sample(range(len(child)), 2)
            child[i], child[j] = child[j], child[i]

        elif mutation_type == 2:  # Inversion mutation
            i, j = sorted(random.sample(range(len(child)), 2))
            child[i:j+1] = reversed(child[i:j+1])

        else:  # Scramble mutation
            i, j = sorted(random.sample(range(len(child)), 2))
            segment = child[i:j+1]
            random.shuffle(segment)
            child[i:j+1] = segment

        return child

    def solve(self, distance_matrix: np.ndarray, verbose: bool = True) -> Tuple[List[int], float]:
        """Main optimization loop"""
        num_cities = len(distance_matrix)
        population = self.initialize_population(num_cities)
        distances = [self.calculate_distance(route, distance_matrix) for route in population]

        # Track best solution
        best_idx = np.argmin(distances)
        self.best_solution = population[best_idx].copy()
        self.best_distance = distances[best_idx]

        for iteration in range(self.max_iterations):
            new_population = []
            new_distances = []

            # Generate new solutions using beagle-inspired operators
            for i in range(self.population_size):
                child = self.sniff_mutate(population[i])
                child_distance = self.calculate_distance(child, distance_matrix)

                new_population.append(child)
                new_distances.append(child_distance)

                # Update best solution
                if child_distance < self.best_distance:
                    self.best_solution = child.copy()
                    self.best_distance = child_distance

            # Environmental selection
            combined_pop = population + new_population
            combined_dist = distances + new_distances
            sorted_indices = np.argsort(combined_dist)

            population = [combined_pop[i] for i in sorted_indices[:self.population_size]]
            distances = [combined_dist[i] for i in sorted_indices[:self.population_size]]

            # Record convergence
            self.convergence_history.append(self.best_distance)

            if verbose and (iteration + 1) % 100 == 0:
                print(f"Iteration {iteration + 1}/{self.max_iterations}, Best Distance: {self.best_distance:.2f}")

        return self.best_solution, self.best_distance

class GOA_TSP_Solver(BaseTSPOptimizer):
    """Grasshopper Optimization Algorithm for TSP"""

    def __init__(self, population_size: int = 50, max_iterations: int = 1000,
                 c_min: float = 0.00001, c_max: float = 1.0):
        super().__init__(population_size, max_iterations)
        self.c_min = c_min
        self.c_max = c_max

    def social_behavior_operator(self, route: List[int], best_route: List[int], c: float) -> List[int]:
        """Grasshopper social behavior operator"""
        new_route = route.copy()

        # Attraction towards best solution
        if random.random() < c:
            # Copy a segment from best solution
            i, j = sorted(random.sample(range(len(route)), 2))
            segment = best_route[i:j+1]

            # Insert the segment
            for city in segment:
                if city in new_route:
                    new_route.remove(city)

            insert_pos = random.randint(0, len(new_route))
            new_route[insert_pos:insert_pos] = segment

        return new_route

    def solve(self, distance_matrix: np.ndarray, verbose: bool = True) -> Tuple[List[int], float]:
        """Main optimization loop"""
        num_cities = len(distance_matrix)
        population = self.initialize_population(num_cities)
        distances = [self.calculate_distance(route, distance_matrix) for route in population]

        # Track best solution
        best_idx = np.argmin(distances)
        self.best_solution = population[best_idx].copy()
        self.best_distance = distances[best_idx]

        for iteration in range(self.max_iterations):
            # Update comfort parameter c
            c = self.c_max - iteration * (self.c_max - self.c_min) / self.max_iterations

            new_population = []
            new_distances = []

            for i in range(self.population_size):
                # Apply social behavior operator
                child = self.social_behavior_operator(population[i], self.best_solution, c)
                child_distance = self.calculate_distance(child, distance_matrix)

                new_population.append(child)
                new_distances.append(child_distance)

                # Update best solution
                if child_distance < self.best_distance:
                    self.best_solution = child.copy()
                    self.best_distance = child_distance

            # Replace population
            population = new_population
            distances = new_distances

            # Record convergence
            self.convergence_history.append(self.best_distance)

            if verbose and (iteration + 1) % 100 == 0:
                print(f"GOA Iteration {iteration + 1}/{self.max_iterations}, Best Distance: {self.best_distance:.2f}")

        return self.best_solution, self.best_distance

class MVO_TSP_Solver(BaseTSPOptimizer):
    """Multi-Verse Optimizer for TSP"""

    def __init__(self, population_size: int = 50, max_iterations: int = 1000,
                 wep_min: float = 0.2, wep_max: float = 1.0):
        super().__init__(population_size, max_iterations)
        self.wep_min = wep_min
        self.wep_max = wep_max

    def wormhole_effect(self, route: List[int], best_route: List[int], wep: float, tdr: float) -> List[int]:
        """Wormhole effect operator"""
        new_route = route.copy()

        for i in range(len(route)):
            if random.random() < wep:
                if random.random() < 0.5:
                    # Move towards best solution
                    if route[i] != best_route[i]:
                        # Swap with best solution's position
                        j = new_route.index(best_route[i])
                        new_route[i], new_route[j] = new_route[j], new_route[i]
                else:
                    # Random exploration
                    if random.random() < tdr:
                        j = random.randint(0, len(route) - 1)
                        new_route[i], new_route[j] = new_route[j], new_route[i]

        return new_route

    def solve(self, distance_matrix: np.ndarray, verbose: bool = True) -> Tuple[List[int], float]:
        """Main optimization loop"""
        num_cities = len(distance_matrix)
        population = self.initialize_population(num_cities)
        distances = [self.calculate_distance(route, distance_matrix) for route in population]

        # Track best solution
        best_idx = np.argmin(distances)
        self.best_solution = population[best_idx].copy()
        self.best_distance = distances[best_idx]

        for iteration in range(self.max_iterations):
            # Update parameters
            wep = self.wep_min + iteration * (self.wep_max - self.wep_min) / self.max_iterations
            tdr = 1 - (iteration ** (1/6)) / (self.max_iterations ** (1/6))

            new_population = []
            new_distances = []

            for i in range(self.population_size):
                # Apply wormhole effect
                child = self.wormhole_effect(population[i], self.best_solution, wep, tdr)
                child_distance = self.calculate_distance(child, distance_matrix)

                new_population.append(child)
                new_distances.append(child_distance)

                # Update best solution
                if child_distance < self.best_distance:
                    self.best_solution = child.copy()
                    self.best_distance = child_distance

            # Replace population
            population = new_population
            distances = new_distances

            # Record convergence
            self.convergence_history.append(self.best_distance)

            if verbose and (iteration + 1) % 100 == 0:
                print(f"MVO Iteration {iteration + 1}/{self.max_iterations}, Best Distance: {self.best_distance:.2f}")

        return self.best_solution, self.best_distance

class LEO_TSP_Solver(BaseTSPOptimizer):
    """Language Education Optimization for TSP"""

    def __init__(self, population_size: int = 50, max_iterations: int = 1000):
        super().__init__(population_size, max_iterations)

    def language_learning_operator(self, student: List[int], teacher: List[int]) -> List[int]:
        """Language learning operator"""
        new_solution = student.copy()

        # Learning from teacher (crossover)
        if random.random() < 0.7:
            # Ordered crossover
            i, j = sorted(random.sample(range(len(student)), 2))
            segment = teacher[i:j+1]

            # Create new solution
            remaining = [city for city in student if city not in segment]
            new_solution = remaining[:i] + segment + remaining[i:]

        # Self-learning (mutation)
        if random.random() < 0.3:
            # Inversion mutation
            i, j = sorted(random.sample(range(len(new_solution)), 2))
            new_solution[i:j+1] = reversed(new_solution[i:j+1])

        return new_solution

    def solve(self, distance_matrix: np.ndarray, verbose: bool = True) -> Tuple[List[int], float]:
        """Main optimization loop"""
        num_cities = len(distance_matrix)
        population = self.initialize_population(num_cities)
        distances = [self.calculate_distance(route, distance_matrix) for route in population]

        # Track best solution (teacher)
        best_idx = np.argmin(distances)
        self.best_solution = population[best_idx].copy()
        self.best_distance = distances[best_idx]

        for iteration in range(self.max_iterations):
            new_population = []
            new_distances = []

            for i in range(self.population_size):
                # Learning process
                if random.random() < 0.8:
                    # Learn from teacher
                    child = self.language_learning_operator(population[i], self.best_solution)
                else:
                    # Learn from another student
                    j = random.randint(0, self.population_size - 1)
                    child = self.language_learning_operator(population[i], population[j])

                child_distance = self.calculate_distance(child, distance_matrix)

                new_population.append(child)
                new_distances.append(child_distance)

                # Update best solution
                if child_distance < self.best_distance:
                    self.best_solution = child.copy()
                    self.best_distance = child_distance

            # Replace population
            population = new_population
            distances = new_distances

            # Record convergence
            self.convergence_history.append(self.best_distance)

            if verbose and (iteration + 1) % 100 == 0:
                print(f"LEO Iteration {iteration + 1}/{self.max_iterations}, Best Distance: {self.best_distance:.2f}")

        return self.best_solution, self.best_distance

def compare_algorithms(problem_sizes: List[int], num_runs: int = 3, max_iterations: int = 1000):
    """Compare all algorithms on different problem sizes"""
    results = {}

    algorithms = {
        'BIOA': BIOA_TSP_Solver(population_size=50, max_iterations=max_iterations),
        'GOA': GOA_TSP_Solver(population_size=50, max_iterations=max_iterations),
        'MVO': MVO_TSP_Solver(population_size=50, max_iterations=max_iterations),
        'LEO': LEO_TSP_Solver(population_size=50, max_iterations=max_iterations)
    }

    for size in problem_sizes:
        print(f"\n{'='*60}")
        print(f"COMPARING ALGORITHMS ON {size}-CITY TSP")
        print(f"{'='*60}")

        # Generate random TSP instance
        np.random.seed(42)
        coordinates = np.random.rand(size, 2) * 100
        dist_matrix = distance_matrix(coordinates, coordinates)

        size_results = {}

        for algo_name, algorithm in algorithms.items():
            print(f"\nTesting {algo_name}...")

            run_times = []
            best_distances = []
            convergence_histories = []

            for run in range(num_runs):
                print(f"  Run {run + 1}/{num_runs}")

                # Reset algorithm for new run
                algorithm.best_solution = None
                algorithm.best_distance = float('inf')
                algorithm.convergence_history = []

                # Time the optimization
                start_time = time.time()
                best_route, best_distance = algorithm.solve(dist_matrix, verbose=False)
                end_time = time.time()

                run_time = end_time - start_time
                run_times.append(run_time)
                best_distances.append(best_distance)
                convergence_histories.append(algorithm.convergence_history.copy())

                print(f"    Best Distance: {best_distance:.2f}")
                print(f"    Time: {run_time:.2f} seconds")

            # Store results for this algorithm
            size_results[algo_name] = {
                'avg_distance': np.mean(best_distances),
                'std_distance': np.std(best_distances),
                'avg_time': np.mean(run_times),
                'std_time': np.std(run_times),
                'convergence': np.mean(convergence_histories, axis=0),
                'best_solution': best_route
            }

        results[size] = size_results

    return results

def plot_comparison_results(results: Dict, problem_sizes: List[int]):
    """Plot comprehensive comparison results"""

    # Create subplots
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

    algorithms = ['BIOA', 'GOA', 'MVO', 'LEO']
    colors = ['blue', 'green', 'red', 'purple']
    markers = ['o', 's', '^', 'D']

    # Plot 1: Solution Quality vs Problem Size
    for i, algo in enumerate(algorithms):
        avg_distances = [results[size][algo]['avg_distance'] for size in problem_sizes]
        ax1.plot(problem_sizes, avg_distances, marker=markers[i], color=colors[i],
                label=algo, linewidth=2, markersize=8)

    ax1.set_xlabel('Problem Size (Number of Cities)')
    ax1.set_ylabel('Average Best Distance')
    ax1.set_title('Solution Quality Comparison')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot 2: Computation Time vs Problem Size
    for i, algo in enumerate(algorithms):
        avg_times = [results[size][algo]['avg_time'] for size in problem_sizes]
        ax2.plot(problem_sizes, avg_times, marker=markers[i], color=colors[i],
                label=algo, linewidth=2, markersize=8)

    ax2.set_xlabel('Problem Size (Number of Cities)')
    ax2.set_ylabel('Average Computation Time (seconds)')
    ax2.set_title('Computation Time Comparison')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Plot 3: Convergence for largest problem size
    largest_size = max(problem_sizes)
    for i, algo in enumerate(algorithms):
        convergence = results[largest_size][algo]['convergence']
        iterations = range(len(convergence))
        ax3.plot(iterations, convergence, color=colors[i], label=algo, linewidth=2)

    ax3.set_xlabel('Iteration')
    ax3.set_ylabel('Best Distance')
    ax3.set_title(f'Convergence Comparison ({largest_size} Cities)')
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # Plot 4: Performance Radar Chart (normalized)
    metrics = ['Solution Quality', 'Computation Speed', 'Convergence Rate']
    categories = metrics * 2

    # Normalize metrics (lower is better for all)
    norm_distances = {}
    norm_times = {}
    norm_conv = {}

    for algo in algorithms:
        # Normalize distances (min-max, inverted)
        dist_values = [results[size][algo]['avg_distance'] for size in problem_sizes]
        norm_distances[algo] = 1 - (np.mean(dist_values) - min([np.mean([results[size][a]['avg_distance'] for size in problem_sizes]) for a in algorithms])) / \
                              (max([np.mean([results[size][a]['avg_distance'] for size in problem_sizes]) for a in algorithms]) -
                               min([np.mean([results[size][a]['avg_distance'] for size in problem_sizes]) for a in algorithms]))

        # Normalize times (min-max, inverted)
        time_values = [results[size][algo]['avg_time'] for size in problem_sizes]
        norm_times[algo] = 1 - (np.mean(time_values) - min([np.mean([results[size][a]['avg_time'] for size in problem_sizes]) for a in algorithms])) / \
                           (max([np.mean([results[size][a]['avg_time'] for size in problem_sizes]) for a in algorithms]) -
                            min([np.mean([results[size][a]['avg_time'] for size in problem_sizes]) for a in algorithms]))

        # Normalize convergence (based on final value)
        conv_values = [results[size][algo]['convergence'][-1] for size in problem_sizes]
        norm_conv[algo] = 1 - (np.mean(conv_values) - min([np.mean([results[size][a]['convergence'][-1] for size in problem_sizes]) for a in algorithms])) / \
                         (max([np.mean([results[size][a]['convergence'][-1] for size in problem_sizes]) for a in algorithms]) -
                          min([np.mean([results[size][a]['convergence'][-1] for size in problem_sizes]) for a in algorithms]))

    # Create radar chart data
    for i, algo in enumerate(algorithms):
        values = [norm_distances[algo], norm_times[algo], norm_conv[algo]]
        values = values + values[:1]  # Close the radar chart

        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
        angles += angles[:1]

        ax4.plot(angles, values, color=colors[i], label=algo, linewidth=2)
        ax4.fill(angles, values, color=colors[i], alpha=0.1)

    ax4.set_xticks(angles[:-1])
    ax4.set_xticklabels(metrics)
    ax4.set_title('Overall Performance Radar Chart')
    ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))

    plt.tight_layout()
    plt.savefig('/content/algorithm_comparison_1200dpi.png', dpi=1200, bbox_inches='tight')
    plt.show()

def print_comparison_table(results: Dict, problem_sizes: List[int]):
    """Print detailed comparison table"""
    print("\n" + "="*100)
    print("COMPREHENSIVE ALGORITHM COMPARISON RESULTS")
    print("="*100)

    algorithms = ['BIOA', 'GOA', 'MVO', 'LEO']

    for size in problem_sizes:
        print(f"\nProblem Size: {size} Cities")
        print("-" * 80)
        print(f"{'Algorithm':<10} {'Avg Distance':<15} {'Std Distance':<15} {'Avg Time (s)':<15} {'Std Time (s)':<15}")
        print("-" * 80)

        for algo in algorithms:
            data = results[size][algo]
            print(f"{algo:<10} {data['avg_distance']:<15.2f} {data['std_distance']:<15.2f} "
                  f"{data['avg_time']:<15.2f} {data['std_time']:<15.2f}")

    # Print overall ranking
    print("\n" + "="*100)
    print("OVERALL RANKING (Lower values are better)")
    print("="*100)

    # Calculate overall scores
    overall_scores = {algo: 0 for algo in algorithms}

    for size in problem_sizes:
        # Rank by distance
        distances = [(algo, results[size][algo]['avg_distance']) for algo in algorithms]
        distances.sort(key=lambda x: x[1])
        for rank, (algo, _) in enumerate(distances, 1):
            overall_scores[algo] += rank

        # Rank by time
        times = [(algo, results[size][algo]['avg_time']) for algo in algorithms]
        times.sort(key=lambda x: x[1])
        for rank, (algo, _) in enumerate(times, 1):
            overall_scores[algo] += rank

    # Print ranking
    sorted_ranking = sorted(overall_scores.items(), key=lambda x: x[1])
    print("\nOverall Ranking (lower score is better):")
    for rank, (algo, score) in enumerate(sorted_ranking, 1):
        print(f"{rank}. {algo}: {score} points")

# Main execution
def main():
    print("BIOA vs Other Optimization Algorithms Comparison")
    print("=" * 60)

    # Create directory for results
    import os
    if not os.path.exists('/content/comparison_results'):
        os.makedirs('/content/comparison_results')

    # Compare algorithms on different problem sizes
    problem_sizes = [20, 50, 100]
    comparison_results = compare_algorithms(problem_sizes, num_runs=3, max_iterations=500)

    # Plot comparison results
    plot_comparison_results(comparison_results, problem_sizes)

    # Print detailed comparison table
    print_comparison_table(comparison_results, problem_sizes)

    # Save results to CSV
    results_df = pd.DataFrame()
    for size in problem_sizes:
        for algo in ['BIOA', 'GOA', 'MVO', 'LEO']:
            results_df = pd.concat([results_df, pd.DataFrame({
                'Algorithm': [algo],
                'Problem_Size': [size],
                'Avg_Distance': [comparison_results[size][algo]['avg_distance']],
                'Std_Distance': [comparison_results[size][algo]['std_distance']],
                'Avg_Time': [comparison_results[size][algo]['avg_time']],
                'Std_Time': [comparison_results[size][algo]['std_time']]
            })])

    results_df.to_csv('/content/comparison_results/algorithm_comparison.csv', index=False)
    print("\nResults saved to /content/comparison_results/algorithm_comparison.csv")

    # Create zip archive
    !zip -r /content/algorithm_comparison_results.zip /content/comparison_results/

    print("\nComparison completed! Download results from:")
    print("/content/algorithm_comparison_results.zip")

if __name__ == "__main__":
    main()
